# Markov Decision Process (MDP) Project 

*Optimization & Uncertainty, Spring 2020*

Markov Decision Processes (MDPs) provide an approach to determining the optimal behavior in maximizing a model’s ability to attain different states that define an environment and can be modeled by several problem. The purpose of this project was to solve a more complicated version of the well-known Grid World problem, an environment in which an agent navigates the environment and chooses actions that maximize the final reward received. We used two common  solution techniques to solve this MDP problem: Value Iteration and Policy Iteration. By using this Grid World problem, we explored the performance of these two algorithms and tested for the comparative performance, as well as the imapct of changing factors, using these solutions. Finally, we wrote a detailed final report, which describes our results of the solutions and and what we found: [Markov Decision Process Report](https://github.com/asarrazin/MDP-/blob/master/MDP_Report.pdf)

# User Instructions

In our main class, named MDP, the user can specify the particular character associated with the particular solution they want to run in the command line, along with the specifications that come with the given solution. The following show the characters with the solution:
* ‘v’ = Value Iteration
* ‘p’ = Policy Iteration

# Built Using

* Java
* BlueJ

# Authors
* Anaïs Sarrazin
* Adrienne Miller

# Acknowledgements
* Professor Majercik 

